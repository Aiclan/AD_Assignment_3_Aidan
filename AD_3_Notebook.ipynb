{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e67fc7d-0cb4-4c6b-b174-d49dba37576d",
   "metadata": {},
   "source": [
    "## Install Llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1ff7b4d2-05cb-45f6-b826-3a5d42e2b660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\ajgre\\anaconda3\\envs\\my\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ajgre\\anaconda3\\envs\\my\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ajgre\\anaconda3\\envs\\my\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ajgre\\anaconda3\\envs\\my\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ajgre\\anaconda3\\envs\\my\\lib\\site-packages (from requests) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "#installed ollama to my device, then using the command line ran llama3, \n",
    "!pip install requests\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97e6f7f-38ec-449e-a5a3-e191968a8fcb",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "616bbf70-0753-4123-86a7-9be8030e73d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A fascinating topic!\n",
      "\n",
      "Large Language Models (LLMs) are a type of artificial intelligence (AI) model that have revolutionized the field of natural language processing (NLP). They are trained on massive amounts of text data and can process and generate human-like language, making them incredibly useful for various applications.\n",
      "\n",
      "**What is a Large Language Model?**\n",
      "\n",
      "A LLM is a type of neural network-based AI model designed to process and generate large volumes of text data. These models are typically trained on massive datasets of text, such as books, articles, and web pages, using techniques like masked language modeling, next sentence prediction, and supervised learning.\n",
      "\n",
      "**Key Characteristics:**\n",
      "\n",
      "1. **Scale**: LLMs are characterized by their enormous size, measured in terms of the number of parameters, which can range from hundreds of millions to billions.\n",
      "2. **Depth**: They have multiple layers of neural network architecture, allowing them to capture complex patterns and relationships in language.\n",
      "3. **Specialized Training**: LLMs are trained on specific tasks, such as language understanding, generation, or translation, using large datasets and advanced training techniques.\n",
      "\n",
      "**Types of Large Language Models:**\n",
      "\n",
      "1. **Autoregressive (AR) Models**: These models generate text one token at a time, predicting the next word based on the context.\n",
      "2. **Transformer-based Models**: These models use self-attention mechanisms to process input sequences in parallel, allowing for faster and more accurate processing.\n",
      "\n",
      "**Applications of Large Language Models:**\n",
      "\n",
      "1. **Language Translation**: LLMs can translate text from one language to another with high accuracy.\n",
      "2. **Text Summarization**: They can summarize long documents into concise summaries.\n",
      "3. **Question Answering**: LLMs can answer natural language questions by finding relevant information in text data.\n",
      "4. **Text Generation**: They can generate human-like text for various applications, such as chatbots, product descriptions, or creative writing.\n",
      "5. **Sentiment Analysis**: LLMs can analyze the sentiment and emotions expressed in text data.\n",
      "6. **Dialogue Systems**: They can engage in natural-sounding conversations with humans.\n",
      "\n",
      "**Challenges and Limitations:**\n",
      "\n",
      "1. **Training Data Quality**: The quality of training data has a significant impact on model performance.\n",
      "2. **Computational Resources**: Training LLMs requires massive computational resources, making it challenging for smaller organizations or individuals.\n",
      "3. **Explainability**: LLMs can be difficult to interpret and understand their decision-making processes.\n",
      "4. **Bias and Fairness**: LLMs can perpetuate biases present in the training data if not properly addressed.\n",
      "\n",
      "**Notable Examples:**\n",
      "\n",
      "1. **BERT (Bidirectional Encoder Representations from Transformers)**: Developed by Google, BERT is a transformer-based model that has achieved state-of-the-art results on various NLP tasks.\n",
      "2. **RoBERTa (Robustly Optimized BERT Pretraining Approach)**: Another transformer-based model developed by Facebook AI, RoBERTa has shown improved performance over BERT on some tasks.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Large Language Models have revolutionized the field of natural language processing, enabling applications that were previously unimaginable. While they present many opportunities, they also pose challenges and limitations. As the technology continues to evolve, we can expect even more exciting developments in the world of AI and NLP!\n"
     ]
    }
   ],
   "source": [
    "#Defining prompt\n",
    "model = 'llama3'\n",
    "prompt= \"Tell me about Large Language Models\"\n",
    "url = 'http://localhost:11434/api/chat'\n",
    "data = {\"model\": model,\"messages\": [{\"role\": \"user\", \"content\": prompt}],\"stream\": False}\n",
    "response= requests.post(url,json=data)\n",
    "\n",
    "#print response\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab175a9-3dce-459e-b9f9-4353872e4ed1",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fbafb14b-1cc0-4243-8c6c-225b2c259fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing modules\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c214cc49-d18a-4e38-8b98-2670f8741010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming file as a variable\n",
    "file = \"genreLyrics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b2ea49d5-c5cc-492c-bc97-8bee440a8c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76301</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Hey, if you were right I'd chase away\\r\\nAll t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>293332</td>\n",
       "      <td>Rock</td>\n",
       "      <td>There's something about the way we fit\\r\\nTher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70683</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>One drop in the ocean\\r\\nCould be that magic p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>209590</td>\n",
       "      <td>Rock</td>\n",
       "      <td>I'm so tired of being here\\r\\nSuppressed by al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116010</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>Yeah, what, Vast Aire,; Shell Shock..\\r\\nIt's ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       genre                                             lyrics\n",
       "0       76301        Rock  Hey, if you were right I'd chase away\\r\\nAll t...\n",
       "1      293332        Rock  There's something about the way we fit\\r\\nTher...\n",
       "2       70683  Electronic  One drop in the ocean\\r\\nCould be that magic p...\n",
       "3      209590        Rock  I'm so tired of being here\\r\\nSuppressed by al...\n",
       "4      116010     Hip-Hop  Yeah, what, Vast Aire,; Shell Shock..\\r\\nIt's ..."
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading and checking df\n",
    "df = pd.read_csv(file, engine = 'python', sep = \"\\t\", encoding = 'utf8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87730ec3-12fd-428f-ae1c-ae1cdac7ff4f",
   "metadata": {},
   "source": [
    "## 1. Zero-Shot Prompt Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7716fd34-b803-4207-94d2-cb0f7f0f9767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification of lyrics using the zero shot prompt method\n",
    "def zero_shot_prompt(lyric, model = 'llama3'):\n",
    "    \n",
    "    prompt= f'''Classify these song lyrics with their associated genre. Only respond with a one-word genre label. Like rock, hip-hop, jazz etc. \n",
    "\n",
    "Lyrics: \n",
    "\\\"\\\"\\\"\n",
    "{lyric}\n",
    "\\\"\\\"\\\"\n",
    "Genre:'''\n",
    "    \n",
    "    url = 'http://localhost:11434/api/chat'\n",
    "    data = {\"model\": model,\"messages\": [{\"role\": \"user\", \"content\": prompt}],\"stream\": False}\n",
    "    response= requests.post(url,json=data)\n",
    "    return response.json()['message']['content'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "eb23e74e-a832-411c-8106-2c76cc0e27e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Indie\n",
      "1       Rock\n",
      "2        Pop\n",
      "3        Emo\n",
      "4    Hip-Hop\n",
      "Name: zero_predicted_genre, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['zero_predicted_genre'] = df['lyrics'].head(5).apply(zero_shot_prompt)\n",
    "print(df['zero_predicted_genre'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584eda1f-c01a-4e2e-9241-efcf098f36fa",
   "metadata": {},
   "source": [
    "## 2. Few-Shot Prompt Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8ca94f5c-623e-4441-b708-b227bbf1e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification of lyrics using the few shot prompt method\n",
    "def few_shot_prompt(lyric, model = 'llama3'):\n",
    "    \n",
    "    prompt= f'''Classify these song lyrics with their associated genre. Only respond with a one-word genre label, like rock, hip-hop, jazz etc. \n",
    "\n",
    "Examples:\n",
    "\n",
    "Lyrics: \n",
    "\\\"\\\"\\\"\n",
    "Stand up beside the fireplace\n",
    "Take that look from off your face\n",
    "\\\"\\\"\\\"\n",
    "Genre: Rock\n",
    "\n",
    "Lyrics: \n",
    "\\\"\\\"\\\"\n",
    "It was all laid out for me\n",
    "But I feel like I'm in love with the pain, fam\n",
    "\\\"\\\"\\\"\n",
    "Genre: Grime\n",
    "\n",
    "Lyrics: \n",
    "\\\"\\\"\\\"\n",
    "Oh you're so naive yet so\n",
    "How could this be done\n",
    "\\\"\\\"\\\"\n",
    "Genre: Indie\n",
    "\n",
    "Now classify these lyrics:\n",
    "\n",
    "Lyrics:\n",
    "\\\"\\\"\\\"\n",
    "{lyric}\n",
    "\\\"\\\"\\\"\n",
    "Genre:'''\n",
    "    \n",
    "    url = 'http://localhost:11434/api/chat'\n",
    "    data = {\"model\": model,\"messages\": [{\"role\": \"user\", \"content\": prompt}],\"stream\": False}\n",
    "    response= requests.post(url,json=data)\n",
    "    return response.json()['message']['content'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3305d75f-31db-43ab-bb4a-acfcc48156a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Indie\n",
      "1        Rap\n",
      "2        Pop\n",
      "3        Emo\n",
      "4    Hip-Hop\n",
      "Name: few_predicted_genre, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['few_predicted_genre'] = df['lyrics'].head(5).apply(few_shot_prompt)\n",
    "print(df['few_predicted_genre'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a493c2d-ad33-4157-a0d1-ac72491654dd",
   "metadata": {},
   "source": [
    "## 3. Calculating the Precision, Recall and F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "1c014a58-4c65-4619-8923-708517768b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making my smaller set for me to perform these measurements on\n",
    "test_df = df.head(5).copy()\n",
    "\n",
    "test_df['genre']\n",
    "test_df['zero_predicted_genre']\n",
    "test_df['few_predicted_genre']\n",
    "\n",
    "y_true = test_df['genre'].str.lower().str.strip()\n",
    "y_pred1 = test_df['zero_predicted_genre'].str.lower().str.strip()\n",
    "y_pred2 = test_df['few_predicted_genre'].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73954e7a-cce9-4625-9b8a-a9b0c82cfefe",
   "metadata": {},
   "source": [
    "## 4. Zero Shot Precision, Recall and F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c9ee1ff5-6802-49a0-838b-9d8b1e8ee66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Shot Precision: 0.8000\n",
      "Zero Shot Recall: 0.4000\n",
      "Zero Shot F1: 0.5000\n"
     ]
    }
   ],
   "source": [
    "#calculating precision, recall and f1 scores\n",
    "zero_precision = precision_score(y_true, y_pred1, average = 'weighted', zero_division = 0)\n",
    "zero_recall = recall_score(y_true, y_pred1, average = 'weighted', zero_division = 0)\n",
    "zero_f1 = f1_score(y_true, y_pred1, average = 'weighted', zero_division = 0)\n",
    "\n",
    "print(f'Zero Shot Precision: {zero_precision:.4f}')\n",
    "print(f'Zero Shot Recall: {zero_recall:.4f}')\n",
    "print(f'Zero Shot F1: {zero_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cce2bc3-b56f-4bc8-a9e2-d35b761b226c",
   "metadata": {},
   "source": [
    "## 5. Few Shot Precision, Recall and F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "2a99ad08-306e-4a84-a36e-bfe92869e116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few Shot Precision: 0.2000\n",
      "Few Shot Recall: 0.2000\n",
      "Few Shot F1: 0.2000\n"
     ]
    }
   ],
   "source": [
    "#calculating precision, recall and f1 scores\n",
    "few_precision = precision_score(y_true, y_pred2, average = 'weighted', zero_division = 0)\n",
    "few_recall = recall_score(y_true, y_pred2, average = 'weighted', zero_division = 0)\n",
    "few_f1 = f1_score(y_true, y_pred2, average = 'weighted', zero_division = 0)\n",
    "\n",
    "print(f'Few Shot Precision: {few_precision:.4f}')\n",
    "print(f'Few Shot Recall: {few_recall:.4f}')\n",
    "print(f'Few Shot F1: {few_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1e6d87f7-0b10-4245-b6b3-48f786713b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        genre zero_predicted_genre few_predicted_genre\n",
      "0        Rock                Indie               Indie\n",
      "1        Rock                 Rock                 Rap\n",
      "2  Electronic                  Pop                 Pop\n",
      "3        Rock                  Emo                 Emo\n",
      "4     Hip-Hop              Hip-Hop             Hip-Hop\n"
     ]
    }
   ],
   "source": [
    "#comparing the results between the correct answer, in genre, and the predicted ones\n",
    "print(test_df[['genre', 'zero_predicted_genre', 'few_predicted_genre']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:my]",
   "language": "python",
   "name": "conda-env-my-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
